{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "chapter -https://huggingface.co/learn/agents-course/unit2/llama-index/tools\n",
        " and https://huggingface.co/learn/agents-course/unit2/llama-index/agents"
      ],
      "metadata": {
        "id": "7CbmRKfkOu25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Toolspec integration"
      ],
      "metadata": {
        "id": "qvRCB3tiPA_1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P9h1ZDQOkY8"
      },
      "outputs": [],
      "source": [
        "pip install llama-index-tools-google"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.tools.google import GmailToolSpec\n",
        "tool_spec=GmailToolSpec()\n",
        "tool_spec_list=tool_spec.to_tool_list()"
      ],
      "metadata": {
        "id": "WVSZT-8WPONW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Agents"
      ],
      "metadata": {
        "id": "Kbj_epXLWHC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index-llms-google-genai llama-index"
      ],
      "metadata": {
        "id": "B-dncme1W59c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent.workflow import AgentWorkflow\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "\n",
        "\n",
        "def multiply(a:int, b:int) ->int:\n",
        "  \"\"\"Multiplies two integers and returns the resulting integer\"\"\"\n",
        "  return a*b\n",
        "\n",
        "llm=GoogleGenAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    api_key=\"AIzaSyByKg5DBFcI166VkQc8Tx0GGwre_0us9TQ\"\n",
        ")\n",
        "agent=AgentWorkflow.from_tools_or_functions(\n",
        "    [FunctionTool.from_defaults(multiply)],\n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "Mygl6CV2WJjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=await agent.run(\"what is 43 time 64 and subtract by 2752?\")\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y3Jn3XnYSs2",
        "outputId": "847d8f35-537f-48c7-894e-8b77fc963618"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='The result of 43 times 64 is 2752. Subtracting 2752 from 2752 gives 0.')]), tool_calls=[ToolCallResult(tool_name='multiply', tool_kwargs={'b': 64, 'a': 43}, tool_id='multiply', tool_output=ToolOutput(content='2752', tool_name='multiply', raw_input={'args': (), 'kwargs': {'b': 64, 'a': 43}}, raw_output=2752, is_error=False), return_direct=False)], raw={'content': {'parts': [{'video_metadata': None, 'thought': None, 'code_execution_result': None, 'executable_code': None, 'file_data': None, 'function_call': None, 'function_response': None, 'inline_data': None, 'text': '2 from 2752 gives 0.'}], 'role': 'model'}, 'citation_metadata': None, 'finish_message': None, 'token_count': None, 'finish_reason': <FinishReason.STOP: 'STOP'>, 'avg_logprobs': None, 'grounding_metadata': None, 'index': None, 'logprobs_result': None, 'safety_ratings': None, 'usage_metadata': {'cache_tokens_details': None, 'cached_content_token_count': None, 'candidates_token_count': 35, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 35}], 'prompt_token_count': 41, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 41}], 'thoughts_token_count': None, 'tool_use_prompt_token_count': None, 'tool_use_prompt_tokens_details': None, 'total_token_count': 76, 'traffic_type': None}}, current_agent_name='Agent')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default Agents are **Stateless** (Means they don't remeber past queries).\n",
        "- To give context, we should give past interactions to maintain and progress over time"
      ],
      "metadata": {
        "id": "qwr0M8CcYxo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.workflow import Context\n",
        "\n",
        "ctx=Context(agent)\n",
        "\n",
        "response=await agent.run(\"My name is Bob\",ctx=ctx)\n",
        "response=await agent.run(\"What's my name?\",ctx=ctx)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xib1ztsRY6BR",
        "outputId": "696dc290-5fc9-45f6-f6b5-2b28f0adeac4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='Your name is Bob.\\n')]), tool_calls=[], raw={'content': {'parts': [{'video_metadata': None, 'thought': None, 'code_execution_result': None, 'executable_code': None, 'file_data': None, 'function_call': None, 'function_response': None, 'inline_data': None, 'text': ' name is Bob.\\n'}], 'role': 'model'}, 'citation_metadata': None, 'finish_message': None, 'token_count': None, 'finish_reason': <FinishReason.STOP: 'STOP'>, 'avg_logprobs': None, 'grounding_metadata': None, 'index': None, 'logprobs_result': None, 'safety_ratings': None, 'usage_metadata': {'cache_tokens_details': None, 'cached_content_token_count': None, 'candidates_token_count': 6, 'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 6}], 'prompt_token_count': 39, 'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>, 'token_count': 39}], 'thoughts_token_count': None, 'tool_use_prompt_token_count': None, 'tool_use_prompt_tokens_details': None, 'total_token_count': 45, 'traffic_type': None}}, current_agent_name='Agent')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}